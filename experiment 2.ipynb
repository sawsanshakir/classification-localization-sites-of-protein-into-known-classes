{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target\n",
      "CYT    463\n",
      "ERL      5\n",
      "EXC     35\n",
      "ME1     44\n",
      "ME2     51\n",
      "ME3    163\n",
      "MIT    244\n",
      "NUC    429\n",
      "POX     20\n",
      "VAC     30\n",
      "dtype: int64\n",
      "[ 0.32136223 25.95        4.325       4.152       2.66153846  0.87966102\n",
      "  0.62155689  0.3448505   6.92        4.71818182]\n"
     ]
    }
   ],
   "source": [
    "### Experiment 2 Class Weights random forest (CWsRF)\n",
    "\n",
    "\n",
    "## the code references \n",
    "\n",
    "## Sullivan W.,2017. Python machine learning illustrated guide for beginners. Healthy pragmatic solutions Inc.\n",
    "##\n",
    "## Liu Y.(Hayden), 2017. Python machine learning by example. Birmingham-Mumbai: Packt.\n",
    "##\n",
    "## Scikit-learn, sklearn.utils.class_weight, available online \n",
    "##https://scikit-learn.org/stable/modules/generated/sklearn.utils.class_weight.compute_class_weight.html. Last accessed 22/04/2019\n",
    "##\n",
    "##Stackoverflow, Scikit-learn, get accuracy scores for each class, \n",
    "##available online https://stackoverflow.com/questions/39770376/scikit-learn-get-accuracy-scores-for-each-class. \n",
    "##Last accessed 22/04/2019\n",
    "## \n",
    "##Medium, AUC ROC Curve Scoring Function for Multi-class Classification, \n",
    "##available online https://medium.com/@plog397/auc-roc-curve-scoring-function-for-multi-class-classification-9822871a6659. \n",
    "##Last accessed 22/04/2019\n",
    "## \n",
    "\n",
    "\n",
    "## This program implement Random Forest with class weights  and split the data to 70% for training and 30% testing\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "\n",
    "yeast_data = pd.read_csv('yeast_data.txt', names= ['mcg','gvh','alm','mit','erl', 'pox','vac','nuc','target'])\n",
    "\n",
    "print(yeast_data.groupby('target').size())\n",
    "\n",
    "## split the data to training and testing datasets (Sullivan,2017)\n",
    "features = yeast_data.iloc[:,0:8].values\n",
    "labels = yeast_data.iloc[:,8].values\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = 0.3, random_state= 0)\n",
    "\n",
    "\n",
    "## weights of the classes(Scikit-learn)\n",
    "class_weight =class_weight.compute_class_weight('balanced', np.unique(train_labels),train_labels)\n",
    "\n",
    "print(class_weight)\n",
    "\n",
    "         \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Soona\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:652: Warning: The least populated class in y has only 4 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "C:\\Users\\Soona\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 20, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 500}\n",
      "0.6107899807321773\n"
     ]
    }
   ],
   "source": [
    "  \n",
    "\n",
    "class_weight = dict({'CYT':0.32136223, 'ERL':25.95    ,'EXC': 4.325 ,'ME1': 4.152   ,'ME2': 2.66153846  ,'ME3': 0.87966102,\n",
    " 'MIT':0.62155689  , 'NUC':0.3448505, 'POX': 6.92   , 'VAC':4.71818182})\n",
    "\n",
    "\n",
    "rf_clf1 = RandomForestClassifier(n_estimators=200, oob_score=True, random_state=10, class_weight = class_weight)\n",
    "     \n",
    "    \n",
    "## Hyper parameters using grid search(Liu Y., 2017)\n",
    "parameters = {'n_estimators' : [100,300,500,700,900],\n",
    "              'max_features' : [\"sqrt\", \"log2\", None],\n",
    "              'max_depth'    : [10, 20, None],\n",
    "              'min_samples_split': [10,30,50]}\n",
    "               \n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "gd_sr = GridSearchCV(estimator= rf_clf1,  \n",
    "                     param_grid=parameters,\n",
    "                     scoring='accuracy',\n",
    "                     cv=5,\n",
    "                     n_jobs=-1)\n",
    "\n",
    "\n",
    "gd_sr.fit( train_features, train_labels)\n",
    "best_parameters = gd_sr.best_params_  \n",
    "print(best_parameters)\n",
    "\n",
    "\n",
    "best_result = gd_sr.best_score_  \n",
    "print(best_result)  \n",
    "\n",
    "## predict the test set using best result \n",
    "predictions = gd_sr.best_estimator_.predict(test_features)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[87  0  0  0  2  4 13 30  1  3]\n",
      " [ 0  1  0  0  0  0  0  0  0  0]\n",
      " [ 1  0  7  0  1  0  1  0  0  1]\n",
      " [ 0  0  1 17  0  1  0  0  0  0]\n",
      " [ 0  1  1  4  4  0  0  1  0  1]\n",
      " [ 2  0  0  0  0 41  0  2  0  0]\n",
      " [14  0  1  0  2  5 45  9  1  0]\n",
      " [35  0  0  0  3  7 10 73  0  0]\n",
      " [ 2  0  0  0  0  0  0  0  3  0]\n",
      " [ 5  0  1  0  0  2  0  0  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         CYT       0.60      0.62      0.61       140\n",
      "         ERL       0.50      1.00      0.67         1\n",
      "         EXC       0.64      0.64      0.64        11\n",
      "         ME1       0.81      0.89      0.85        19\n",
      "         ME2       0.33      0.33      0.33        12\n",
      "         ME3       0.68      0.91      0.78        45\n",
      "         MIT       0.65      0.58      0.62        77\n",
      "         NUC       0.63      0.57      0.60       128\n",
      "         POX       0.60      0.60      0.60         5\n",
      "         VAC       0.00      0.00      0.00         8\n",
      "\n",
      "   micro avg       0.62      0.62      0.62       446\n",
      "   macro avg       0.54      0.62      0.57       446\n",
      "weighted avg       0.62      0.62      0.62       446\n",
      "\n",
      "accuracy_score 0.6233183856502242\n",
      "\n",
      "accuracy of each class\n",
      "\n",
      "[0.62142857 1.         0.63636364 0.89473684 0.33333333 0.91111111\n",
      " 0.58441558 0.5703125  0.6        0.        ]\n",
      "Area under curve ROC is:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7829599662981508"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#comparison = pd.DataFrame({'Real':test_labels, 'Predictions': predictions})\n",
    "#print(comparison)\n",
    "\n",
    "## find accuracy and confusion matrix (Sullivan,2017)\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(confusion_matrix(test_labels, predictions))\n",
    "print(classification_report(test_labels, predictions))\n",
    "print(\"accuracy_score\" , accuracy_score(test_labels, predictions))\n",
    "print( )\n",
    "\n",
    "\n",
    "### find the accuracy of each class (Stackoverflow)\n",
    "cm = confusion_matrix(test_labels, predictions)\n",
    "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "print (\"accuracy of each class\")\n",
    "print()\n",
    "print(cm.diagonal())\n",
    "\n",
    "### calculate the avarage auc_roc for the classes(Medium) \n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "def multiclass_roc_auc_score(truth, pred, average=\"macro\"):\n",
    "\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(truth)\n",
    "\n",
    "    truth = lb.transform(truth)\n",
    "    pred = lb.transform(pred)\n",
    "\n",
    "    return roc_auc_score(truth, pred, average=average)\n",
    "\n",
    "print(\"Area under curve ROC is:\")\n",
    "multiclass_roc_auc_score(test_labels, predictions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
