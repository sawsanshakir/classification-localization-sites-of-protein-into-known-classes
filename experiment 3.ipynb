{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target\n",
      "CYT    463\n",
      "ERL      5\n",
      "EXC     35\n",
      "ME1     44\n",
      "ME2     51\n",
      "ME3    163\n",
      "MIT    244\n",
      "NUC    429\n",
      "POX     20\n",
      "VAC     30\n",
      "dtype: int64\n",
      "the balance classes\n",
      "\n",
      "[('CYT', 323), ('ERL', 323), ('EXC', 323), ('ME1', 323), ('ME2', 323), ('ME3', 323), ('MIT', 323), ('NUC', 323), ('POX', 323), ('VAC', 323)]\n",
      "{'max_depth': 20, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 900}\n",
      " the best result is\n",
      "0.8708978328173375\n",
      "[[81  0  0  0  3  3 13 33  2  5]\n",
      " [ 0  1  0  0  0  0  0  0  0  0]\n",
      " [ 1  0  7  0  1  0  1  0  0  1]\n",
      " [ 0  0  0 15  1  1  0  0  1  1]\n",
      " [ 2  0  0  3  5  1  0  0  0  1]\n",
      " [ 0  0  1  0  1 39  0  3  1  0]\n",
      " [11  0  1  0  2  5 47  9  1  1]\n",
      " [35  0  1  0  3  7  9 73  0  0]\n",
      " [ 1  0  0  0  0  0  0  1  3  0]\n",
      " [ 5  0  1  0  0  2  0  0  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         CYT       0.60      0.58      0.59       140\n",
      "         ERL       1.00      1.00      1.00         1\n",
      "         EXC       0.64      0.64      0.64        11\n",
      "         ME1       0.83      0.79      0.81        19\n",
      "         ME2       0.31      0.42      0.36        12\n",
      "         ME3       0.67      0.87      0.76        45\n",
      "         MIT       0.67      0.61      0.64        77\n",
      "         NUC       0.61      0.57      0.59       128\n",
      "         POX       0.38      0.60      0.46         5\n",
      "         VAC       0.00      0.00      0.00         8\n",
      "\n",
      "   micro avg       0.61      0.61      0.61       446\n",
      "   macro avg       0.57      0.61      0.58       446\n",
      "weighted avg       0.61      0.61      0.61       446\n",
      "\n",
      "0.6076233183856502\n",
      "accuracy of each class\n",
      "\n",
      "[0.57857143 1.         0.63636364 0.78947368 0.41666667 0.86666667\n",
      " 0.61038961 0.5703125  0.6        0.        ]\n",
      "Area under curve ROC is:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7780443387028415"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "### Experiment 3 Over Sampling random forest (OSRF)\n",
    "\n",
    "\n",
    "## the code references \n",
    "\n",
    "## Sullivan W.,2017. Python machine learning illustrated guide for beginners. Healthy pragmatic solutions Inc.\n",
    "##\n",
    "## Liu Y.(Hayden), 2017. Python machine learning by example. Birmingham-Mumbai: Packt.\n",
    "##\n",
    "##Imbalanced-learn, imblearn.over_sampling.SMOTE ,available online \n",
    "##https://imbalanced-learn.readthedocs.io/en/stable/generated/imblearn.over_sampling.SMOTE.html, Last accessed 22/04/2019\n",
    "##\n",
    "##Stackoverflow, Scikit-learn, get accuracy scores for each class, \n",
    "##available online https://stackoverflow.com/questions/39770376/scikit-learn-get-accuracy-scores-for-each-class. \n",
    "##Last accessed 22/04/2019\n",
    "## \n",
    "##Medium, AUC ROC Curve Scoring Function for Multi-class Classification, \n",
    "##available online https://medium.com/@plog397/auc-roc-curve-scoring-function-for-multi-class-classification-9822871a6659. \n",
    "##Last accessed 22/04/2019\n",
    "## \n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold # import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "\n",
    "yeast_data = pd.read_csv('yeast_data.txt', names= ['mcg','gvh','alm','mit','erl', 'pox','vac','nuc','target'])\n",
    "\n",
    "## split the data to training and testing datasets (Sullivan,2017)\n",
    "print(yeast_data.groupby('target').size())\n",
    "features = yeast_data.iloc[:,0:8].values\n",
    "labels = yeast_data.iloc[:,8].values\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = 0.3, random_state= 0)\n",
    "\n",
    "########################################################################\n",
    "\n",
    "## oversampling by SMOTE algorithm to balance the training data set(Imbalanced-learn)\n",
    "\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote= SMOTE(sampling_strategy = 'not majority', random_state= 2, k_neighbors = 2)\n",
    "new_train_features, new_train_labels = smote.fit_sample(train_features, train_labels)\n",
    "print (\"the balance classes\")\n",
    "print()\n",
    "print(sorted(Counter(new_train_labels).items()))\n",
    "\n",
    "###################################################################################\n",
    "\n",
    "## fit the balance training data to random forest and tuning the parameters by grid search(Liu Y., 2017)\n",
    "\n",
    "rf_clf = RandomForestClassifier(n_estimators=200, oob_score=True, random_state=10) \n",
    "\n",
    "\n",
    "parameters = {'n_estimators' : [100,300,500,700,900],\n",
    "              'max_features' : [\"sqrt\", \"log2\", None],\n",
    "              'max_depth'    : [10, 20, None],\n",
    "              'min_samples_split': [10,30,50] }\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "gd_sr = GridSearchCV(estimator= rf_clf,  \n",
    "                     param_grid=parameters,\n",
    "                     scoring='accuracy',\n",
    "                     cv=5,\n",
    "                     n_jobs= -1)\n",
    "\n",
    "gd_sr.fit( new_train_features, new_train_labels)\n",
    "best_parameters = gd_sr.best_params_  \n",
    "print(best_parameters)\n",
    "\n",
    "best_result = gd_sr.best_score_  \n",
    "print (\" the best result is\")\n",
    "print(best_result)  \n",
    "\n",
    "################################################################################################\n",
    "\n",
    "## predict the imbalanced test set using best result from grid search\n",
    "predictions = gd_sr.best_estimator_.predict(test_features)\n",
    "\n",
    "\n",
    "## find accuracy and confusion matrix (Sullivan,2017)\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(confusion_matrix(test_labels, predictions))\n",
    "print(classification_report(test_labels, predictions))\n",
    "print(accuracy_score(test_labels, predictions))\n",
    "\n",
    "\n",
    "### find the accuracy of each class (Stackoverflow)\n",
    "cm = confusion_matrix(test_labels, predictions)\n",
    "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "print (\"accuracy of each class\")\n",
    "print()\n",
    "print(cm.diagonal())\n",
    "  \n",
    "\n",
    "### calculate the avarage auc_roc for the classes(Medium)\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "def multiclass_roc_auc_score(truth, pred, average=\"macro\"):\n",
    "    \n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(truth)\n",
    "\n",
    "    truth = lb.transform(truth)\n",
    "    pred = lb.transform(pred)\n",
    "\n",
    "    return roc_auc_score(truth, pred, average=average)\n",
    "\n",
    "print(\"Area under curve ROC is:\")\n",
    "multiclass_roc_auc_score(test_labels, predictions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
