{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Soona\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:652: Warning: The least populated class in y has only 4 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "C:\\Users\\Soona\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 10, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 300}\n",
      "0.6117533718689788\n",
      "[[101   0   0   0   2   3   6  26   1   1]\n",
      " [  0   1   0   0   0   0   0   0   0   0]\n",
      " [  3   0   7   0   1   0   0   0   0   0]\n",
      " [  0   0   2  14   1   1   0   0   1   0]\n",
      " [  3   0   1   2   4   0   2   0   0   0]\n",
      " [  2   0   0   0   0  40   0   3   0   0]\n",
      " [ 19   0   0   0   2   4  46   6   0   0]\n",
      " [ 42   0   0   0   2   6   9  69   0   0]\n",
      " [  2   0   0   0   0   0   0   0   3   0]\n",
      " [  5   0   1   0   0   2   0   0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         CYT       0.57      0.72      0.64       140\n",
      "         ERL       1.00      1.00      1.00         1\n",
      "         EXC       0.64      0.64      0.64        11\n",
      "         ME1       0.88      0.74      0.80        19\n",
      "         ME2       0.33      0.33      0.33        12\n",
      "         ME3       0.71      0.89      0.79        45\n",
      "         MIT       0.73      0.60      0.66        77\n",
      "         NUC       0.66      0.54      0.59       128\n",
      "         POX       0.60      0.60      0.60         5\n",
      "         VAC       0.00      0.00      0.00         8\n",
      "\n",
      "   micro avg       0.64      0.64      0.64       446\n",
      "   macro avg       0.61      0.61      0.61       446\n",
      "weighted avg       0.64      0.64      0.63       446\n",
      "\n",
      "accuracy_score 0.6390134529147982\n",
      "\n",
      "accuracy of each class\n",
      "\n",
      "[0.72142857 1.         0.63636364 0.73684211 0.33333333 0.88888889\n",
      " 0.5974026  0.5390625  0.6        0.        ]\n",
      "the avarage Area under curve ROC is:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7784895670629237"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Experiment 1 Random Forest (RF)\n",
    "\n",
    "## the code references \n",
    "\n",
    "## Sullivan W.,2017. Python machine learning illustrated guide for beginners. Healthy pragmatic solutions Inc.\n",
    "##\n",
    "## Liu Y.(Hayden), 2017. Python machine learning by example. Birmingham-Mumbai: Packt.\n",
    "##\n",
    "##Stackoverflow, Scikit-learn, get accuracy scores for each class, \n",
    "##available online https://stackoverflow.com/questions/39770376/scikit-learn-get-accuracy-scores-for-each-class. \n",
    "##Last accessed 22/04/2019\n",
    "## \n",
    "##Medium, AUC ROC Curve Scoring Function for Multi-class Classification, \n",
    "##available online https://medium.com/@plog397/auc-roc-curve-scoring-function-for-multi-class-classification-9822871a6659. \n",
    "##Last accessed 22/04/2019\n",
    "## \n",
    "\n",
    "\n",
    "\n",
    "## This program first implement Random Forest  with imblanced data using grid search to tuning the parameters and predict the accuracy  \n",
    "## split the data to 70% training set and 30% test set\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "## split the data to training and testing datasets (Sullivan,2017)\n",
    "\n",
    "yeast_data = pd.read_csv('yeast_data.txt', names= ['mcg','gvh','alm','mit','erl', 'pox','vac','nuc','target'])\n",
    "\n",
    "features = yeast_data.iloc[:,0:8].values\n",
    "labels = yeast_data.iloc[:,8].values\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = 0.3, random_state= 0)\n",
    "\n",
    "###########################################################################################\n",
    "\n",
    "rf_clf = RandomForestClassifier(n_estimators=200, oob_score=True ,random_state=10)   \n",
    "\n",
    "## Hyper parameter using grid search(Liu, 2017)\n",
    "\n",
    "parameters = {'n_estimators' : [100,300,500,700,900],\n",
    "              'max_features' : [\"sqrt\", \"log2\", None],\n",
    "              'max_depth'    : [10, 20, None],\n",
    "              'min_samples_split': [2,5,10] }\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "gd_sr = GridSearchCV(estimator= rf_clf,  \n",
    "                     param_grid=parameters,\n",
    "                     scoring='accuracy',\n",
    "                     cv=5,\n",
    "                     n_jobs=-1)\n",
    "\n",
    "\n",
    "gd_sr.fit( train_features, train_labels)\n",
    "best_parameters = gd_sr.best_params_  \n",
    "print(best_parameters)\n",
    "\n",
    "\n",
    "best_result = gd_sr.best_score_  \n",
    "print(best_result)  \n",
    "\n",
    "###########################################################################\n",
    "\n",
    "## predict the test set using best result\n",
    "\n",
    "predictions = gd_sr.best_estimator_.predict(test_features)\n",
    "\n",
    "#comparison = pd.DataFrame({'Real':test_labels, 'Predictions': predictions})\n",
    "#print(comparison)\n",
    "\n",
    "\n",
    "## find accuracy and confusion matrix (Sullivan,2017)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(confusion_matrix(test_labels, predictions))\n",
    "print(classification_report(test_labels, predictions))\n",
    "print(\"accuracy_score\" , accuracy_score(test_labels, predictions))\n",
    "print( )\n",
    "\n",
    "\n",
    "### find the accuracy of each class (Stackoverflow)\n",
    "\n",
    "cm = confusion_matrix(test_labels, predictions)\n",
    "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "print (\"accuracy of each class\")\n",
    "print()\n",
    "print(cm.diagonal())\n",
    "\n",
    " \n",
    "### calculate the avarage auc_roc for the classes(Medium)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "def multiclass_roc_auc_score(truth, pred, average=\"macro\"):\n",
    "\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(truth)\n",
    "\n",
    "    truth = lb.transform(truth)\n",
    "    pred = lb.transform(pred)\n",
    "\n",
    "    return roc_auc_score(truth, pred, average=average)\n",
    "\n",
    "print(\"the avarage Area under curve ROC is:\")\n",
    "multiclass_roc_auc_score(test_labels, predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
