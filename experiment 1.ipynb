{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 1 Random Forest (RF)\n",
    "\n",
    "## the code references \n",
    "\n",
    "## Sullivan W.,2017. Python machine learning illustrated guide for beginners. Healthy pragmatic solutions Inc.\n",
    "##\n",
    "## Liu Y.(Hayden), 2017. Python machine learning by example. Birmingham-Mumbai: Packt.\n",
    "##\n",
    "##Stackoverflow, Scikit-learn, get accuracy scores for each class, \n",
    "##available online https://stackoverflow.com/questions/39770376/scikit-learn-get-accuracy-scores-for-each-class. \n",
    "##Last accessed 22/04/2019\n",
    "## \n",
    "##Medium, AUC ROC Curve Scoring Function for Multi-class Classification, \n",
    "##available online https://medium.com/@plog397/auc-roc-curve-scoring-function-for-multi-class-classification-9822871a6659. \n",
    "##Last accessed 22/04/2019\n",
    "## \n",
    "\n",
    "\n",
    "\n",
    "## This program first implement Random Forest  with imblanced data using grid search to tuning the parameters and predict the accuracy  \n",
    "## split the data to 70% training set and 30% test set\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "## split the data to training and testing datasets (Sullivan,2017)\n",
    "\n",
    "yeast_data = pd.read_csv('yeast_data.txt', names= ['mcg','gvh','alm','mit','erl', 'pox','vac','nuc','target'])\n",
    "\n",
    "features = yeast_data.iloc[:,0:8].values\n",
    "labels = yeast_data.iloc[:,8].values\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = 0.3, random_state= 0)\n",
    "\n",
    "###########################################################################################\n",
    "\n",
    "rf_clf = RandomForestClassifier(n_estimators=200, oob_score=True ,random_state=10)   \n",
    "\n",
    "## Hyper parameter using grid search(Liu, 2017)\n",
    "\n",
    "parameters = {'n_estimators' : [100,300,500,700,900],\n",
    "              'max_features' : [\"sqrt\", \"log2\", None],\n",
    "              'max_depth'    : [10, 20, None],\n",
    "              'min_samples_split': [2,5,10] }\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "gd_sr = GridSearchCV(estimator= rf_clf,  \n",
    "                     param_grid=parameters,\n",
    "                     scoring='accuracy',\n",
    "                     cv=5,\n",
    "                     n_jobs=-1)\n",
    "\n",
    "\n",
    "gd_sr.fit( train_features, train_labels)\n",
    "best_parameters = gd_sr.best_params_  \n",
    "print(best_parameters)\n",
    "\n",
    "\n",
    "best_result = gd_sr.best_score_  \n",
    "print(best_result)  \n",
    "\n",
    "###########################################################################\n",
    "\n",
    "## predict the test set using best result\n",
    "\n",
    "predictions = gd_sr.best_estimator_.predict(test_features)\n",
    "\n",
    "#comparison = pd.DataFrame({'Real':test_labels, 'Predictions': predictions})\n",
    "#print(comparison)\n",
    "\n",
    "\n",
    "## find accuracy and confusion matrix (Sullivan,2017)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(confusion_matrix(test_labels, predictions))\n",
    "print(classification_report(test_labels, predictions))\n",
    "print(\"accuracy_score\" , accuracy_score(test_labels, predictions))\n",
    "print( )\n",
    "\n",
    "\n",
    "### find the accuracy of each class (Stackoverflow)\n",
    "\n",
    "cm = confusion_matrix(test_labels, predictions)\n",
    "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "print (\"accuracy of each class\")\n",
    "print()\n",
    "print(cm.diagonal())\n",
    "\n",
    " \n",
    "### calculate the avarage auc_roc for the classes(Medium)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "def multiclass_roc_auc_score(truth, pred, average=\"macro\"):\n",
    "\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(truth)\n",
    "\n",
    "    truth = lb.transform(truth)\n",
    "    pred = lb.transform(pred)\n",
    "\n",
    "    return roc_auc_score(truth, pred, average=average)\n",
    "\n",
    "print(\"the avarage Area under curve ROC is:\")\n",
    "multiclass_roc_auc_score(test_labels, predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
